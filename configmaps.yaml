apiVersion: v1
data:
  .env: FINNHUB_TOKEN = d03aeb1r01qvvb9384c0d03aeb1r01qvvb9384cg
  __init__.py: ""
  config.py: "from dotenv import load_dotenv\nimport os \nimport yaml \nload_dotenv('/project/.env')\n\n\n\nclass
    Config :\n    with open('/project/config/config.yml','r') as file:\n        config_data
    = yaml.load(file , Loader=yaml.FullLoader)\n\n        producer_config = config_data[\"PRODUCER\"]['PRODUCER_CONFIG']\n
    \       topic_name = config_data[\"PRODUCER\"]['TOPIC_NAME']\n        server =
    config_data[\"CONSUMER\"]['SERVER']\n\n\n\n\n        finnhub_token = os.getenv('FINNHUB_TOKEN')\n\n\n\n\n\n\n\nconfig
    = Config()    \n#print(config.finnhub_token)"
  config.yml: |-
    PRODUCER:
      PRODUCER_CONFIG: {'bootstrap.servers': 'kafka:9092'}
      TOPIC_NAME: 'finnhub_trades'

    CONSUMER:
      SERVER: 'kafka:9092'
  consumer.py: "from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import
    col, from_json, current_timestamp, avg, count, window\nfrom pyspark.sql.types
    import StructType, StructField, StringType, DoubleType, LongType , ArrayType\nimport
    logging\nfrom cassandra.cluster import Cluster, NoHostAvailable\nimport uuid\nfrom
    config.config import config\n\nlogger = logging.getLogger(__name__)\n\ndef store_cassandra_raw(batch_df,
    batch_id):\n    cluster = None\n    try:\n        logger.info(f'Storing raw batch
    {batch_id} in Cassandra')\n        cluster = Cluster(['cassandra'], port=9042)\n
    \       session = cluster.connect()\n\n        session.execute(\"CREATE KEYSPACE
    IF NOT EXISTS fintech WITH replication = {'class': 'SimpleStrategy', 'replication_factor':
    1}\")\n        session.set_keyspace(\"fintech\")\n        \n        session.execute(\"\"\"CREATE
    TABLE IF NOT EXISTS fintech.trades (\n            id uuid PRIMARY KEY,\n            symbol
    text,\n            price double,\n            volume double,\n            trade_timestamp
    bigint,\n            ingestion_time timestamp\n        )\"\"\")\n\n        df
    = batch_df.select(\n            col(\"symbol\").alias(\"symbol\"),\n            col(\"price\").alias(\"price\"),\n
    \           col(\"volume\").alias(\"volume\"),\n            col(\"timestamp\").alias(\"trade_timestamp\"),\n
    \           current_timestamp().alias(\"ingestion_time\")\n        )\n\n        logger.info(f'Starting
    to insert raw data for batch {batch_id}')\n        rows = df.collect()\n        for
    row in rows:\n            session.execute(\n                \"\"\"INSERT INTO
    fintech.trades (id, symbol, price, volume, trade_timestamp, ingestion_time)\n
    \               VALUES (%s, %s, %s, %s, %s, %s)\"\"\",\n                (uuid.uuid4(),
    row[\"symbol\"], row[\"price\"], row[\"volume\"], row[\"trade_timestamp\"], row[\"ingestion_time\"])\n
    \           )\n        logger.info(f'Inserted {len(rows)} raw rows into Cassandra
    for batch {batch_id}')\n\n    except NoHostAvailable as e:\n        logger.exception(f'Cassandra
    connection failed for raw batch {batch_id}: {e}')\n    except Exception as e:\n
    \       logger.exception(f'Cassandra raw processing error for batch {batch_id}:
    {e}')\n    finally:\n        if cluster:\n            cluster.shutdown()\n\ndef
    store_cassandra_aggregated(batch_df, batch_id):\n    cluster = None\n    try:\n
    \       logger.info(f'Storing aggregated batch {batch_id} in Cassandra, row count:
    {batch_df.count()}')\n        if batch_df.count() == 0:\n            logger.info(f'No
    data in aggregated batch {batch_id}')\n            return\n\n        cluster =
    Cluster(['cassandra'], port=9042)\n        session = cluster.connect()\n        session.set_keyspace(\"fintech\")\n\n
    \       session.execute(\"\"\"CREATE TABLE IF NOT EXISTS fintech.trade_aggregations
    (\n            window_start timestamp,\n            window_end timestamp,\n            symbol
    text,\n            avg_price double,\n            trade_count bigint,\n            PRIMARY
    KEY (window_start, symbol)\n        )\"\"\")\n\n        df = batch_df.select(\n
    \           col(\"window.start\").alias(\"window_start\"),\n            col(\"window.end\").alias(\"window_end\"),\n
    \           col(\"symbol\").alias(\"symbol\"),\n            col(\"avg_price\").alias(\"avg_price\"),\n
    \           col(\"trade_count\").alias(\"trade_count\")\n        )\n\n        logger.info(f'Starting
    to insert aggregated data for batch {batch_id}')\n        rows = df.collect()\n
    \       for row in rows:\n            session.execute(\n                \"\"\"INSERT
    INTO fintech.trade_aggregations (window_start, window_end, symbol, avg_price,
    trade_count)\n                VALUES (%s, %s, %s, %s, %s)\"\"\",\n                (row[\"window_start\"],
    row[\"window_end\"], row[\"symbol\"], row[\"avg_price\"], row[\"trade_count\"])\n
    \           )\n        logger.info(f'Inserted {len(rows)} aggregated rows into
    Cassandra for batch {batch_id}')\n\n    except NoHostAvailable as e:\n        logger.exception(f'Cassandra
    connection failed for aggregated batch {batch_id}: {e}')\n    except Exception
    as e:\n        logger.exception(f'Cassandra aggregated processing error for batch
    {batch_id}: {e}')\n    finally:\n        if cluster:\n            cluster.shutdown()\n\ndef
    consumer():\n    spark = None\n    try:\n        logger.info('Starting the consumer')\n
    \       spark = SparkSession.builder.appName(\"FinStreamProcessing\").config(\"spark.jars.packages\",
    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\").getOrCreate()\n        logger.info('Spark
    session created successfully')\n\n        schema = StructType([\n            StructField(\"data\",
    ArrayType(StructType([\n                StructField(\"c\", StringType(), True),\n
    \               StructField(\"p\", DoubleType(), True),\n                StructField(\"s\",
    StringType(), True),\n                StructField(\"t\", LongType(), True),\n
    \               StructField(\"v\", DoubleType(), True)\n            ])), True),\n
    \           StructField(\"type\", StringType(), True)\n        ])\n\n        df
    = spark.readStream.format('kafka').option(\"kafka.bootstrap.servers\", config.server).option(\"subscribe\",
    config.topic_name).option(\"startingOffsets\", \"earliest\").option(\"group.id\",
    \"finstream-group\").load()\n\n        df = df.select(from_json(col(\"value\").cast(\"string\"),
    schema).alias(\"data\")) \\\n               .selectExpr(\"explode(data.data) as
    trade\") \\\n               .select(\n                   col(\"trade.s\").alias(\"symbol\"),\n
    \                  col(\"trade.p\").alias(\"price\"),\n                   col(\"trade.v\").alias(\"volume\"),\n
    \                  col(\"trade.t\").alias(\"timestamp\")\n               )\n\n
    \       # First Query: Write raw data to Cassandra\n        raw_query = df.writeStream.foreachBatch(store_cassandra_raw).outputMode('append').start()\n
    \       logger.info('Raw data streaming query started')\n\n        # Second Query:
    Aggregations every 5 seconds\n        aggregated_df = df.groupBy(window((col(\"timestamp\")
    / 1000).cast(\"timestamp\"), \"5 seconds\"),col(\"symbol\")).agg(avg(\"price\").alias(\"avg_price\"),count(\"*\").alias(\"trade_count\"))\n\n
    \       agg_query = aggregated_df.writeStream.foreachBatch(store_cassandra_aggregated).outputMode('update').start()\n
    \       logger.info('Aggregated data streaming query started')\n\n        spark.streams.awaitAnyTermination()\n\n
    \   except Exception as e:\n        logger.exception(f'Consumer error: {e}')\n
    \   finally:\n        if spark:\n            spark.stop()\n\n\nconsumer()"
  producer.py: |-
    from confluent_kafka import Producer
    from confluent_kafka.admin import AdminClient, NewTopic
    import json
    import logging
    import websocket
    from config.config import config

    logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', filename="/project/log/app.log", filemode='a')
    logger = logging.getLogger(__name__)

    def report(err, msg):
        if err is not None:
            logger.error(f'Message failed from the producer: {err}')
        else:
            logger.info(f'Message delivered to: topic = {msg.topic()} & partition = {msg.partition()}')

    def on_message(ws, message):
        try:
            logger.info(f'Received WebSocket message: {message}')
            producer.produce(config.topic_name, value=message, callback=report)
            producer.flush()
        except Exception as e:
            logger.error(f'Error producing message to Kafka: {e}')

    def on_error(ws, error):
        logger.error(f'WebSocket error: {error}')

    def on_close(ws, close_status_code, close_msg):
        logger.info(f'WebSocket closed: {close_status_code}, {close_msg}')

    def on_open(ws):
        logger.info('WebSocket connection opened')
        ws.send('{"type":"subscribe","symbol":"AAPL"}')
        ws.send('{"type":"subscribe","symbol":"AMZN"}')
        ws.send('{"type":"subscribe","symbol":"BINANCE:BTCUSDT"}')
        ws.send('{"type":"subscribe","symbol":"IC MARKETS:1"}')

    def producer():
        global producer
        try:
            admin = AdminClient(config.producer_config)
            if config.topic_name not in admin.list_topics().topics:
                topic = NewTopic(config.topic_name, num_partitions=1, replication_factor=1)
                admin.create_topics([topic])
                logger.info(f'Topic created: {config.topic_name}')
            else:
                logger.info(f'Topic already exists: {config.topic_name}')

            # initialize Kafka producer
            producer = Producer(config.producer_config)

            # start WebSocket connection
            websocket.enableTrace(False)
            ws = websocket.WebSocketApp(
                f"wss://ws.finnhub.io?token={config.finnhub_token}",
                on_message=on_message,
                on_error=on_error,
                on_close=on_close
            )
            ws.on_open = on_open
            ws.run_forever()  # Runs indefinitely, keeping container alive

        except Exception as e:
            logger.exception('Producer error')

    producer()
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: project-files
  namespace: finstream
apiVersion: v1
data:
  app.py: "import streamlit as st\nimport pandas as pd\nimport plotly.express as px\nfrom
    cassandra.cluster import Cluster\nfrom cassandra.query import SimpleStatement\nfrom
    cassandra.policies import DCAwareRoundRobinPolicy\nfrom datetime import datetime,
    timedelta\nimport time\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger
    = logging.getLogger(__name__)\n\n# Streamlit page configuration\nst.set_page_config(page_title=\"FinStream
    Real-Time Dashboard\", layout=\"centered\")\n\n# Initialize Cassandra connection\n@st.cache_resource\ndef
    init_cassandra():\n    try:\n        cluster = Cluster(\n            ['cassandra'],\n
    \           port=9042,\n            load_balancing_policy=DCAwareRoundRobinPolicy(local_dc='datacenter1'),\n
    \           protocol_version=4\n        )\n        session = cluster.connect('fintech')\n
    \       logger.info(\"Connected to Cassandra\")\n        return session\n    except
    Exception as e:\n        logger.error(f\"Cassandra connection failed: {str(e)}\")\n
    \       st.error(f\"Cannot connect to Cassandra: {str(e)}\")\n        return None\n\n#
    Pie Chart: Trade Count Proportion (fintech.trade_aggregations)\ndef fetch_trade_count(session,
    time_window_minutes=10):\n    try:\n        query = \"\"\"\n        SELECT symbol,
    trade_count\n        FROM trade_aggregations\n        WHERE window_start > %s
    AND window_start < %s\n        ALLOW FILTERING\n        \"\"\"\n        end_time
    = datetime.utcnow()\n        start_time = end_time - timedelta(minutes=time_window_minutes)\n
    \       statement = SimpleStatement(query)\n        rows = session.execute(statement,
    [start_time, end_time])\n        \n        df = pd.DataFrame(rows, columns=['symbol',
    'trade_count'])\n        df = df.groupby('symbol')['trade_count'].sum().reset_index()\n
    \       df.columns = ['Symbol', 'Total Trades']\n        return df\n    except
    Exception as e:\n        logger.error(f\"Error fetching trade count: {str(e)}\")\n
    \       st.error(f\"Error fetching trade count: {str(e)}\")\n        return pd.DataFrame()\n\n#
    Stat Chart: Latest Trade Price (fintech.trades)\ndef fetch_latest_price(session,
    time_window_minutes=5):\n    try:\n        query = \"\"\"\n        SELECT symbol,
    price\n        FROM trades\n        WHERE ingestion_time >= %s\n        ALLOW
    FILTERING\n        \"\"\"\n        end_time = datetime.utcnow()\n        start_time
    = end_time - timedelta(minutes=time_window_minutes)\n        statement = SimpleStatement(query)\n
    \       rows = session.execute(statement, [start_time])\n        \n        df
    = pd.DataFrame(rows, columns=['symbol', 'price'])\n        df = df.groupby('symbol')['price'].last().reset_index()\n
    \       df.columns = ['Symbol', 'Latest Price']\n        return df\n    except
    Exception as e:\n        logger.error(f\"Error fetching latest price: {str(e)}\")\n
    \       st.error(f\"Error fetching latest price: {str(e)}\")\n        return pd.DataFrame()\n\n#
    Line Chart: Trade Count Trend (fintech.trades)\ndef fetch_trade_count_trend(session,
    time_window_minutes=15):\n    try:\n        query = \"\"\"\n        SELECT ingestion_time,
    symbol\n        FROM trades\n        WHERE ingestion_time > %s AND ingestion_time
    < %s\n        ALLOW FILTERING\n        \"\"\"\n        end_time = datetime.utcnow()\n
    \       start_time = end_time - timedelta(minutes=time_window_minutes)\n        statement
    = SimpleStatement(query)\n        rows = session.execute(statement, [start_time,
    end_time])\n        \n        df = pd.DataFrame(rows, columns=['ingestion_time',
    'symbol'])\n        df = df.groupby(['ingestion_time', 'symbol']).size().reset_index(name='Trade
    Count')\n        df.columns = ['Time', 'Symbol', 'Trade Count']\n        return
    df\n    except Exception as e:\n        logger.error(f\"Error fetching trade count
    trend: {str(e)}\")\n        st.error(f\"Error fetching trade count trend: {str(e)}\")\n
    \       return pd.DataFrame()\n\n# Area Chart: Total Volume Trend by Symbol (fintech.trades)\ndef
    fetch_volume_trend(session, time_window_minutes=15):\n    try:\n        query
    = \"\"\"\n        SELECT ingestion_time, symbol, volume\n        FROM trades\n
    \       WHERE ingestion_time > %s AND ingestion_time < %s\n        ALLOW FILTERING\n
    \       \"\"\"\n        end_time = datetime.utcnow()\n        start_time = end_time
    - timedelta(minutes=time_window_minutes)\n        statement = SimpleStatement(query)\n
    \       rows = session.execute(statement, [start_time, end_time])\n        \n
    \       df = pd.DataFrame(rows, columns=['ingestion_time', 'symbol', 'volume'])\n
    \       df = df.groupby(['ingestion_time', 'symbol'])['volume'].sum().reset_index()\n
    \       df.columns = ['Time', 'Symbol', 'Total Volume']\n        return df\n    except
    Exception as e:\n        logger.error(f\"Error fetching volume trend: {str(e)}\")\n
    \       st.error(f\"Error fetching volume trend: {str(e)}\")\n        return pd.DataFrame()\n\n#
    Line Chart: Price Trend Over Time (fintech.trades)\ndef fetch_price_trend(session,
    time_window_minutes=15):\n    try:\n        query = \"\"\"\n        SELECT ingestion_time,
    symbol, price\n        FROM trades\n        WHERE ingestion_time > %s AND ingestion_time
    < %s\n        ALLOW FILTERING\n        \"\"\"\n        end_time = datetime.utcnow()\n
    \       start_time = end_time - timedelta(minutes=time_window_minutes)\n        statement
    = SimpleStatement(query)\n        rows = session.execute(statement, [start_time,
    end_time])\n        \n        df = pd.DataFrame(rows, columns=['ingestion_time',
    'symbol', 'price'])\n        df = df.groupby(['ingestion_time', 'symbol'])['price'].mean().reset_index()\n
    \       df.columns = ['Time', 'Symbol', 'Price']\n        return df\n    except
    Exception as e:\n        logger.error(f\"Error fetching price trend: {str(e)}\")\n
    \       st.error(f\"Error fetching price trend: {str(e)}\")\n        return pd.DataFrame()\n\n#
    Main app\ndef main():\n    session = init_cassandra()\n    if session is None:\n
    \       st.stop()\n\n    # Header\n    st.markdown(\n        \"<h1 style='text-align:
    center; margin-bottom: 20px; font-size: 2.5em;'>FinStream Real-Time Dashboard</h1>\",\n
    \       unsafe_allow_html=True\n    )\n\n    # Sidebar\n    st.sidebar.markdown(\n
    \       \"<h2 style='font-size: 1.5em; margin-bottom: 10px;'>Dashboard Controls</h2>\",\n
    \       unsafe_allow_html=True\n    )\n    st.sidebar.markdown(\"---\")\n    time_window
    = st.sidebar.slider(\n        \"Time Window (minutes)\",\n        min_value=1,\n
    \       max_value=60,\n        value=5,\n        help=\"Set the time range for
    data displayed in charts.\"\n    )\n    refresh_interval = st.sidebar.slider(\n
    \       \"Refresh Interval (seconds)\",\n        min_value=1,\n        max_value=30,\n
    \       value=5,\n        help=\"Set how often the dashboard refreshes with new
    data.\"\n    )\n    st.sidebar.markdown(\"### Visualization Settings\")\n    precision_toggle
    = st.sidebar.checkbox(\n        \"Round Price Metrics\",\n        value=True,\n
    \       help=\"Round prices to 2 decimal places or show full precision.\"\n    )\n
    \   notify_toggle = st.sidebar.checkbox(\n        \"Refresh Notifications\",\n
    \       value=False,\n        help=\"Show a notification when the dashboard refreshes.\"\n
    \   )\n\n    # Latest Trade Prices (always visible)\n    st.markdown(\n        \"<h3
    style='text-align: center; margin-bottom: 10px;'>Latest Trade Prices</h3>\",\n
    \       unsafe_allow_html=True\n    )\n    prices_placeholder = st.empty()\n\n
    \   # Expanders for charts\n    pie_expander = st.expander(\"Trade Count Proportion\",
    expanded=False)\n    count_expander = st.expander(\"Trade Count Trend\", expanded=False)\n
    \   area_expander = st.expander(\"Volume Trend Over Time\", expanded=False)\n
    \   price_trend_expander = st.expander(\"Price Trend Over Time\", expanded=False)\n\n
    \   # Placeholders for charts\n    with pie_expander:\n        pie_placeholder
    = st.empty()\n    with count_expander:\n        count_placeholder = st.empty()\n
    \   with area_expander:\n        area_placeholder = st.empty()\n    with price_trend_expander:\n
    \       price_trend_placeholder = st.empty()\n\n    # Update loop (friend's refresh
    logic)\n    iteration = 0\n    while True:\n        key_suffix = f\"{iteration}_{int(time.time())}\"\n\n
    \       # Latest Trade Prices\n        with prices_placeholder.container():\n
    \           df_stat = fetch_latest_price(session, time_window)\n            if
    not df_stat.empty:\n                cols = st.columns(len(df_stat))  # One column
    per symbol\n                for idx, row in df_stat.iterrows():\n                    with
    cols[idx]:\n                        price = row['Latest Price']\n                        display_price
    = f\"${price:.2f}\" if precision_toggle else f\"${price}\"\n                        st.metric(\n
    \                           label=f\"Latest Price for {row['Symbol']}\",\n                            value=display_price\n
    \                       )\n            else:\n                st.warning(\"No
    latest price data available.\")\n\n        # Pie Chart\n        with pie_placeholder.container():\n
    \           df_pie = fetch_trade_count(session, time_window)\n            if not
    df_pie.empty:\n                fig_pie = px.pie(\n                    df_pie,\n
    \                   names='Symbol',\n                    values='Total Trades',\n
    \                   title='',\n                    height=300\n                )\n
    \               fig_pie.update_layout(margin=dict(l=20, r=20, t=20, b=20))\n                st.plotly_chart(fig_pie,
    use_container_width=True, key=f\"pie_chart_{key_suffix}\")\n            else:\n
    \               st.warning(\"No trade count data available.\")\n\n        # Line
    Chart (Trade Count)\n        with count_placeholder.container():\n            df_count
    = fetch_trade_count_trend(session, time_window)\n            if not df_count.empty:\n
    \               fig_count = px.line(\n                    df_count,\n                    x='Time',\n
    \                   y='Trade Count',\n                    color='Symbol',\n                    title='',\n
    \                   labels={'Trade Count': 'Number of Trades', 'Time': 'Time'},\n
    \                   height=300\n                )\n                fig_count.update_layout(margin=dict(l=20,
    r=20, t=20, b=20))\n                st.plotly_chart(fig_count, use_container_width=True,
    key=f\"count_chart_{key_suffix}\")\n            else:\n                st.warning(\"No
    trade count trend data available.\")\n\n        # Area Chart\n        with area_placeholder.container():\n
    \           df_area = fetch_volume_trend(session, time_window)\n            if
    not df_area.empty:\n                fig_area = px.area(\n                    df_area,\n
    \                   x='Time',\n                    y='Total Volume',\n                    color='Symbol',\n
    \                   title='',\n                    labels={'Total Volume': 'Volume
    (Shares)', 'Time': 'Time'},\n                    height=300\n                )\n
    \               fig_area.update_layout(margin=dict(l=20, r=20, t=20, b=20))\n
    \               st.plotly_chart(fig_area, use_container_width=True, key=f\"area_chart_{key_suffix}\")\n
    \           else:\n                st.warning(\"No volume trend data available.\")\n\n
    \       # Line Chart (Price Trend)\n        with price_trend_placeholder.container():\n
    \           df_price = fetch_price_trend(session, time_window)\n            if
    not df_price.empty:\n                fig_price = px.line(\n                    df_price,\n
    \                   x='Time',\n                    y='Price',\n                    color='Symbol',\n
    \                   title='',\n                    labels={'Price': 'Price ($)',
    'Time': 'Time'},\n                    height=300\n                )\n                fig_price.update_layout(margin=dict(l=20,
    r=20, t=20, b=20))\n                st.plotly_chart(fig_price, use_container_width=True,
    key=f\"price_trend_chart_{key_suffix}\")\n            else:\n                st.warning(\"No
    price trend data available.\")\n\n        # Show refresh notification if enabled\n
    \       if notify_toggle:\n            st.toast(f\"Dashboard refreshed at {datetime.now().strftime('%H:%M:%S')}\",
    icon=\"\U0001F504\")\n\n        # Increment iteration and wait\n        iteration
    += 1\n        time.sleep(refresh_interval)\n\nmain()"
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: streamlit-app
  namespace: finstream
